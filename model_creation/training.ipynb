{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import T5TokenizerFast, TFT5ForConditionalGeneration\n",
    "from progressbar import progressbar as pb\n",
    "\n",
    "def essai(i):  \n",
    "  A=tokenizer(inputbatch[i],padding='max_length',return_tensors='tf').input_ids\n",
    "  B=model.generate(A)\n",
    "  print(inputbatch[i])\n",
    "  return print(tokenizer.decode(B[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "data = pd.read_csv('new_dataset.csv',index_col=0)\n",
    "data['JOB']=data.JOB1+' '+data.JOB\n",
    "data=data.drop(columns=['JOB1','GPE','TENSE'])\n",
    "data=data[(data.txt.str.len()<80) & (data.JOB.notna()) & (data.PERSON!=data.ORG)]\n",
    "# data=data[['txt','PERSON','NORP','JOB','ORG']]\n",
    "data=shuffle(data).dropna()\n",
    "\n",
    "\n",
    "df_input = data.iloc[:,1:]\n",
    "df_label = data.iloc[:,0:1]\n",
    "\n",
    "n = (len(df_input)//100)*100\n",
    "print(n)\n",
    "print(len(df_input))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1700\n",
      "1706\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model = TFT5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "tokenizer = T5TokenizerFast.from_pretrained(\"t5-base\")\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-10 08:55:31.873376: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-08-10 08:55:31.873902: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-08-10 08:55:31.874129: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (HAL-9000): /proc/driver/nvidia/version does not exist\n",
      "2021-08-10 08:55:31.878320: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-10 08:55:31.932626: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "batch_size=32\n",
    "num_of_batches=math.floor(n/batch_size)\n",
    "\n",
    "label=[df_label.values[i][0] for i in range (len(data))]\n",
    "label_encoded=tokenizer.batch_encode_plus(label,padding=True,max_length=900,return_tensors='tf')[\"input_ids\"]\n",
    "\n",
    "inputbatch=['|'.join(df_input.iloc[i].dropna().values.tolist()) for i in range (len(data))]\n",
    "input_encoded=tokenizer.batch_encode_plus(inputbatch,padding=True,max_length=900,return_tensors='tf')[\"input_ids\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "epoch=2\n",
    "los=[]\n",
    "for k in range(epoch):\n",
    "\n",
    "    running_loss=0\n",
    "    \n",
    "    \n",
    "    for i in pb(range(num_of_batches)):\n",
    "        input=input_encoded[i*batch_size:i*batch_size+batch_size]\n",
    "        output=label_encoded[i*batch_size:i*batch_size+batch_size]\n",
    "        \n",
    "        #Entrainement sur le batch\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = model(input_ids=input, labels=output)\n",
    "            # Compute the loss value for this batch.\n",
    "            loss_value = sum(outputs.loss)/len(outputs.loss)\n",
    "            running_loss+=loss_value\n",
    "        # Actualisation des poids\n",
    "        gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100% (53 of 53) |########################| Elapsed Time: 1:21:23 Time:  1:21:23\n",
      "100% (53 of 53) |########################| Elapsed Time: 1:01:30 Time:  1:01:30\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "A=tokenizer(\"Teddy Riner|french|judo player\",padding='max_length',return_tensors='tf').input_ids\n",
    "B=model.generate(A)\n",
    "print(tokenizer.decode(B[0]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<pad> Teddy Riner is a French former judo player</s>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "model.save_pretrained(\"../model\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "c88a35e465b325a4868a83a019894d34a5393f3a0b841abdb6ae197bdcab3f20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}