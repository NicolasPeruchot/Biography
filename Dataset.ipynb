{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python373jvsc74a57bd02c389fa4cf50b850ad874e3b9b3165a376e69045109ccdeae25cb1aa36938185",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "ca3246a3c8e83b87b3df0b73736644c8280d5b382a6c9272defde1b8977a365a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from icecream import ic\n",
    "import spacy\n",
    "import progressbar\n",
    "from spacy.matcher import Matcher, DependencyMatcher\n",
    "# !python -m spacy download en_core_web_sm\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('dataframe_true_final.csv')\n",
    "text=data['txt']\n",
    "data=data.drop(columns=['Unnamed: 0','txt','id'])\n",
    "text=text.str.replace(\"'\",\"\",regex=False)\n",
    "text=text.str.replace(\"]\",\"\",regex=False)\n",
    "text=text.str.replace(\"[\",\"\",regex=False)\n",
    "text=text.str.replace(\",\",\"\",regex=False)\n",
    "text=text.str.replace(\"A \",\"a \",regex=False)\n",
    "text=text.str.replace(\"And\",\"and\",regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata=pd.DataFrame(index=text.index, columns=['PERSON','JOB','NORP','GPE','ORG'])\n",
    "\n",
    "matcher_nom=DependencyMatcher(nlp.vocab)\n",
    "pattern_nom=[[{\"RIGHT_ID\":\"nom\",\"RIGHT_ATTRS\":{\"DEP\":\"nsubj\"}},{\"LEFT_ID\":\"nom\",\"REL_OP\":\">\",\"RIGHT_ID\":\"reste\",\"RIGHT_ATTRS\":{}}]]\n",
    "matcher_nom.add(\"nom\",pattern_nom)\n",
    "\n",
    "matcher_job = Matcher(nlp.vocab)\n",
    "pattern_job = [[{\"DEP\": \"attr\"}]]\n",
    "matcher_job.add(\"JOB\", pattern_job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100% (100 of 100) |######################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "wrong=set()\n",
    "for i in progressbar.progressbar(range (100)):\n",
    "  doc=nlp(text[i])\n",
    "  A=matcher_nom(doc)\n",
    "  B=matcher_job(doc)\n",
    "  if A!=[]:   \n",
    "    newdata.loc[i]['PERSON']=doc[A[0][1][1]:A[0][1][0]+1].text\n",
    "  else: \n",
    "    wrong.add(i)\n",
    "  if B!=[]:   \n",
    "    newdata.loc[i]['JOB']=doc[B[0][1]:B[0][2]].text\n",
    "  else: \n",
    "    wrong.add(i)\n",
    "\n",
    "\n",
    "  for col in ['NORP','GPE','ORG']:\n",
    "    for ent in doc.ents:\n",
    "      if ent.label_==col and newdata.iloc[i][col]!=newdata.iloc[i][col]:\n",
    "        newdata.loc[i][col]=ent.text\n",
    "\n",
    "\n",
    "\n",
    "for df in [newdata, text]:\n",
    "  df.drop(wrong).reset_index().drop(columns=['index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def essai(i): #tester le nouveau dataset\n",
    "  ic(newdata.iloc[i])\n",
    "  ic(text[i])\n",
    "  doc=nlp(text[i])\n",
    "  for ent in doc.ents:\n",
    "    ic(ent.text)\n",
    "    ic(ent.label_)\n",
    "  for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ic| newdata.iloc[i]: PERSON    NaN\n",
      "                     JOB       NaN\n",
      "                     NORP      NaN\n",
      "                     GPE       NaN\n",
      "                     ORG       NaN\n",
      "                     Name: 470, dtype: object\n",
      "ic| text[i]: 'Gregor Amann is a German politician and member Of the SPD'\n",
      "ic| ent.text: 'Gregor Amann'\n",
      "ic| ent.label_: 'PERSON'\n",
      "ic| ent.text: 'German'\n",
      "ic| ent.label_: 'NORP'\n",
      "ic| ent.text: 'SPD'\n",
      "ic| ent.label_: 'GPE'\n",
      "Gregor PROPN compound Amann\n",
      "Amann PROPN nsubj is\n",
      "is AUX ROOT is\n",
      "a DET det politician\n",
      "German ADJ amod politician\n",
      "politician NOUN attr is\n",
      "and CCONJ cc politician\n",
      "member NOUN conj politician\n",
      "Of ADP prep politician\n",
      "the DET det SPD\n",
      "SPD PROPN pobj Of\n"
     ]
    }
   ],
   "source": [
    "essai(470)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([text,newdata],axis=1).to_csv('New_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matcher_job=DependencyMatcher(nlp.vocab)\n",
    "# pattern_job=[[{\"RIGHT_ID\":\"nom\",\"RIGHT_ATTRS\":{\"DEP\":\"attr\"}},{\"LEFT_ID\":\"nom\",\"REL_OP\":\">>\",\"RIGHT_ID\":\"reste\",\"RIGHT_ATTRS\":{}}]]\n",
    "# matcher_job.add(\"nom\",pattern_job)\n",
    "\n",
    "matcher_job=DependencyMatcher(nlp.vocab)\n",
    "pattern_job=[[{\"RIGHT_ID\":\"gauche\",\"RIGHT_ATTRS\":{}},{\"LEFT_ID\":\"gauche\",\"REL_OP\":\"<<\",\"RIGHT_ID\":\"job\",\"RIGHT_ATTRS\":{\"DEP\":\"attr\"}},{\"LEFT_ID\":\"job\",\"REL_OP\":\">\",\"RIGHT_ID\":\"reste\",\"RIGHT_ATTRS\":{}}]]\n",
    "matcher_job.add(\"nom\",pattern_job)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ic| doc: Denis Oswald is a Swiss rower and sports official\n",
      "ic| doc[min(A[j][1])+1:max(A[j][1])+1]: Swiss rower and sports\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Swiss rower and sports"
      ]
     },
     "metadata": {},
     "execution_count": 245
    }
   ],
   "source": [
    "doc=nlp(text[4888])\n",
    "ic(doc)\n",
    "A=matcher_job(doc)\n",
    "long=[]\n",
    "for i in range(len(A)):\n",
    "    long.append(max(A[i][1])-min(A[i][1]))\n",
    "j=long.index(max(long))\n",
    "ic(doc[min(A[j][1])+1:max(A[j][1])+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3, 7, 11]"
      ]
     },
     "metadata": {},
     "execution_count": 223
    }
   ],
   "source": [
    "min(A[7][1]):max(A[7][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ic| j: 0\n",
      "ic| Z[j:j+1]: German\n",
      "ic| j: 0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 167
    }
   ],
   "source": [
    "\n",
    "Z=doc[i[1][1]:i[1][0]+1]\n",
    "for j in range(len(Z)):\n",
    "    ic(j)\n",
    "    ic(Z[j:j+1])\n",
    "    if Z[j:j+1].ents!=[]:\n",
    "        if Z[j:j+1].ents[0].label_=='NORP':\n",
    "            break\n",
    "\n",
    "ic(j)"
   ]
  }
 ]
}