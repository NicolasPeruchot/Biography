{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python373jvsc74a57bd02c389fa4cf50b850ad874e3b9b3165a376e69045109ccdeae25cb1aa36938185",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "ca3246a3c8e83b87b3df0b73736644c8280d5b382a6c9272defde1b8977a365a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from icecream import ic\n",
    "import spacy\n",
    "import progressbar\n",
    "from spacy.matcher import Matcher\n",
    "# !python -m spacy download en_core_web_sm\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('dataframe_true_final.csv')\n",
    "text=data['txt']\n",
    "data=data.drop(columns=['Unnamed: 0','txt','id'])\n",
    "text=text.str.replace(\"'\",\"\",regex=False)\n",
    "text=text.str.replace(\"]\",\"\",regex=False)\n",
    "text=text.str.replace(\"[\",\"\",regex=False)\n",
    "text=text.str.replace(\",\",\"\",regex=False)\n",
    "text=text.str.replace(\"A \",\"a \",regex=False)\n",
    "text=text.str.replace(\"And\",\"and\",regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata=pd.DataFrame(index=text.index, columns=['PERSON','NORP','GPE','ORG','JOB'])\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern_nom = [[{\"DEP\": \"compound\", \"OP\": \"*\"},{\"DEP\": \"nsubj\"}]]\n",
    "matcher.add(\"NOM\", pattern_nom)\n",
    "\n",
    "matcher_job = Matcher(nlp.vocab)\n",
    "pattern_job = [[{\"DEP\": \"attr\"}]]\n",
    "matcher_job.add(\"JOB\", pattern_job)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100% (317268 of 317268) |################| Elapsed Time: 0:47:03 Time:  0:47:03\n"
     ]
    }
   ],
   "source": [
    "wrong=set()\n",
    "for i in progressbar.progressbar(range (len(text))):\n",
    "  doc=nlp(text[i])\n",
    "  A=matcher(doc)\n",
    "  B=matcher_job(doc)\n",
    "  if A!=[]:   \n",
    "    newdata.loc[i]['PERSON']=doc[A[0][1]:A[0][2]].text\n",
    "  else: \n",
    "    wrong.add(i)\n",
    "  if B!=[]:   \n",
    "    newdata.loc[i]['JOB']=doc[B[0][1]:B[0][2]].text\n",
    "  else: \n",
    "    wrong.add(i)\n",
    "\n",
    "\n",
    "  for col in ['NORP','GPE','ORG']:\n",
    "    for ent in doc.ents:\n",
    "      if ent.label_==col and newdata.iloc[i][col]!=newdata.iloc[i][col]:\n",
    "        newdata.loc[i][col]=ent.text\n",
    "\n",
    "\n",
    "\n",
    "for df in [newdata, text]:\n",
    "  df.drop(wrong).reset_index().drop(columns=['index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def essai(i): #tester le nouveau dataset\n",
    "  ic(new.iloc[i])\n",
    "  ic(text[i])\n",
    "  doc=nlp(text[i])\n",
    "  for ent in doc.ents:\n",
    "    ic(ent.text)\n",
    "    ic(ent.label_)\n",
    "  for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata.to_csv('New_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}